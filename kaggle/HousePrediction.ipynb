{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLw+qg8y9SF3MxIM17AMxl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/generalpacific/zerotohero/blob/main/kaggle/HousePrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add Imports"
      ],
      "metadata": {
        "id": "Fb-MSCDkOYQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "import sklearn.linear_model\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "iHLhJwHZOZtG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read dataset and print the shapes"
      ],
      "metadata": {
        "id": "x9ae3KsfOemE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "feature_names = df.columns\n",
        "X = df.iloc[:, :-1].values\n",
        "Y = df.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "pfU-HUKTRabe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Feature Names: \")\n",
        "print(feature_names)\n",
        "print(\"Features Matrix (X):\")\n",
        "print(X[:2])\n",
        "print(\"Feature vector size: \")\n",
        "print(X.shape)\n",
        "print(\"\\nTarget Vector (Y):\")\n",
        "print(Y[:2])"
      ],
      "metadata": {
        "id": "uwfPMEg2OxOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36aa114d-318a-410a-8ad6-5cd77f5ac031"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Names: \n",
            "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
            "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
            "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
            "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
            "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
            "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
            "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
            "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
            "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
            "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
            "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
            "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
            "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
            "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
            "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
            "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
            "       'SaleCondition', 'SalePrice'],\n",
            "      dtype='object')\n",
            "Features Matrix (X):\n",
            "[[1 60 'RL' 65.0 8450 'Pave' nan 'Reg' 'Lvl' 'AllPub' 'Inside' 'Gtl'\n",
            "  'CollgCr' 'Norm' 'Norm' '1Fam' '2Story' 7 5 2003 2003 'Gable' 'CompShg'\n",
            "  'VinylSd' 'VinylSd' 'BrkFace' 196.0 'Gd' 'TA' 'PConc' 'Gd' 'TA' 'No'\n",
            "  'GLQ' 706 'Unf' 0 150 856 'GasA' 'Ex' 'Y' 'SBrkr' 856 854 0 1710 1 0 2\n",
            "  1 3 1 'Gd' 8 'Typ' 0 nan 'Attchd' 2003.0 'RFn' 2 548 'TA' 'TA' 'Y' 0 61\n",
            "  0 0 0 0 nan nan nan 0 2 2008 'WD' 'Normal']\n",
            " [2 20 'RL' 80.0 9600 'Pave' nan 'Reg' 'Lvl' 'AllPub' 'FR2' 'Gtl'\n",
            "  'Veenker' 'Feedr' 'Norm' '1Fam' '1Story' 6 8 1976 1976 'Gable'\n",
            "  'CompShg' 'MetalSd' 'MetalSd' 'None' 0.0 'TA' 'TA' 'CBlock' 'Gd' 'TA'\n",
            "  'Gd' 'ALQ' 978 'Unf' 0 284 1262 'GasA' 'Ex' 'Y' 'SBrkr' 1262 0 0 1262 0\n",
            "  1 2 0 3 1 'TA' 6 'Typ' 1 'TA' 'Attchd' 1976.0 'RFn' 2 460 'TA' 'TA' 'Y'\n",
            "  298 0 0 0 0 0 nan nan nan 0 5 2007 'WD' 'Normal']]\n",
            "Feature vector size: \n",
            "(1460, 80)\n",
            "\n",
            "Target Vector (Y):\n",
            "[208500 181500]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### See features"
      ],
      "metadata": {
        "id": "2JtuGb15OmvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### See Unique values per column"
      ],
      "metadata": {
        "id": "A9fJyyGMS3rS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_ranges(series, num_bins=20):\n",
        "    min_val, max_val = series.min(), series.max()\n",
        "    range_step = (max_val - min_val) / num_bins\n",
        "    ranges = [f\"{min_val + range_step * i:.2f} - {min_val + range_step * (i+1):.2f}\" for i in range(num_bins)]\n",
        "    return ranges\n",
        "\n",
        "def print_ranges(df):\n",
        "  for column in df.columns:\n",
        "      unique_values = df[column].unique()\n",
        "\n",
        "      if unique_values.size > 20 and np.issubdtype(df[column].dtype, np.number):\n",
        "            print(f\"Column '{column}' has more than 20 unique numeric values. Creating ranges:\")\n",
        "            print(create_ranges(df[column]))\n",
        "      else:\n",
        "        print(f\"Unique values in '{column}':\")\n",
        "        print(unique_values)\n",
        "      print()\n",
        "\n",
        "#print_ranges(df)"
      ],
      "metadata": {
        "id": "LJsRjbfQOpLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Check for Nans"
      ],
      "metadata": {
        "id": "OQymkpXSbZaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_nans(df):\n",
        "  df_numeric = df.select_dtypes(include=[np.number])\n",
        "  df[df_numeric.columns] = df_numeric.fillna(0)\n",
        "  return df\n",
        "\n",
        "df = replace_nans(df)"
      ],
      "metadata": {
        "id": "zovtjadPboCP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering"
      ],
      "metadata": {
        "id": "16eNG8YcOp1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessDataset(df):\n",
        "  numerical_data = df.select_dtypes(include=['int64', 'float64'])\n",
        "  categorical_data = df.select_dtypes(include=['object'])\n",
        "\n",
        "  sale_price_col = pd.DataFrame()\n",
        "  if 'SalePrice' in df.columns:\n",
        "    sale_price_col = df.SalePrice\n",
        "\n",
        "\n",
        "  # One hot encoding for categories\n",
        "  categorical_data_encoded = pd.get_dummies(categorical_data)\n",
        "\n",
        "  # Apply Standard Scaling to numerical data\n",
        "  scaler = StandardScaler()\n",
        "  numerical_data_scaled = scaler.fit_transform(numerical_data)\n",
        "  numerical_data_scaled_df = pd.DataFrame(numerical_data_scaled, columns=numerical_data.columns)\n",
        "\n",
        "  preprocessed_df = pd.concat([numerical_data_scaled_df, categorical_data_encoded], axis=1)\n",
        "  preprocessed_df.drop('Id', axis=1, inplace=True)\n",
        "  if 'SalePrice' in df.columns:\n",
        "    preprocessed_df.drop('SalePrice', axis=1, inplace=True)\n",
        "  return preprocessed_df, sale_price_col\n",
        "\n",
        "preprocessed_df, Y = preprocessDataset(df)\n",
        "#print(preprocessed_df)"
      ],
      "metadata": {
        "id": "QiNJmrnROtFd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_X = preprocessed_df.iloc[:, :].values\n"
      ],
      "metadata": {
        "id": "IzigsJNq7fek"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(preprocessed_X.shape)\n",
        "\n",
        "print(\"examples preprocessed_X:\")\n",
        "print(preprocessed_X[:2])\n",
        "\n",
        "print(Y.shape)\n",
        "print(\"examples of Y: \")\n",
        "print(Y[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aabSEXKg6kfq",
        "outputId": "4d0ef247-f5b9-4fe8-b1d2-c0409ae26282"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1460, 288)\n",
            "examples preprocessed_X:\n",
            "[[ 0.07337496  0.2128772  -0.20714171  0.65147924 -0.51719981  1.05099379\n",
            "   0.87866809  0.51410389  0.57542484 -0.28865283 -0.94459061 -0.45930254\n",
            "  -0.79343379  1.16185159 -0.12024172  0.37033344  1.10781015 -0.24106104\n",
            "   0.78974052  1.22758538  0.16377912 -0.21145358  0.91220977 -0.95122649\n",
            "   0.29602618  0.31172464  0.35100032 -0.75217584  0.21650316 -0.3593249\n",
            "  -0.11633929 -0.27020835 -0.06869175 -0.08768781 -1.5991111   0.13877749\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   1.          0.          0.          0.          0.          0.\n",
            "   1.          0.          0.          0.          1.          1.\n",
            "   0.          0.          0.          0.          0.          1.\n",
            "   1.          0.          0.          0.          0.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   1.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   1.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          1.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          0.\n",
            "   0.          1.          0.          0.          1.          0.\n",
            "   0.          0.          0.          0.          1.          0.\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   0.          1.          0.          0.          1.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          1.          0.          1.          0.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          1.          0.          0.          1.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   1.          0.          0.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          0.\n",
            "   1.          0.          0.          1.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          1.          0.        ]\n",
            " [-0.87256276  0.64574726 -0.09188637 -0.07183611  2.17962776  0.15673371\n",
            "  -0.42957697 -0.57075013  1.17199212 -0.28865283 -0.64122799  0.46646492\n",
            "   0.25714043 -0.79516323 -0.12024172 -0.48251191 -0.81996437  3.94880935\n",
            "   0.78974052 -0.76162067  0.16377912 -0.21145358 -0.31868327  0.60049493\n",
            "   0.23649474  0.31172464 -0.06073101  1.62619479 -0.70448325 -0.3593249\n",
            "  -0.11633929 -0.27020835 -0.06869175 -0.08768781 -0.48911005 -0.61443862\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   1.          0.          0.          0.          0.          0.\n",
            "   1.          0.          0.          0.          1.          1.\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   1.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          1.          0.          1.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   0.          0.          0.          0.          1.          0.\n",
            "   0.          0.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          1.          0.          1.          0.          0.\n",
            "   0.          0.          0.          0.          1.          0.\n",
            "   0.          0.          0.          1.          0.          1.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          1.          0.          1.          0.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   1.          0.          0.          0.          0.          1.\n",
            "   0.          1.          0.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          0.\n",
            "   1.          0.          0.          1.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          1.          0.        ]]\n",
            "(1460,)\n",
            "examples of Y: \n",
            "0    208500\n",
            "1    181500\n",
            "Name: SalePrice, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train"
      ],
      "metadata": {
        "id": "xRjhQu2DZryX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (preprocessed_X.shape[1],)\n",
        "model = Sequential([\n",
        "    Dense(2024, input_shape=input_shape),\n",
        "    Dense(1024),\n",
        "    Dense(512),\n",
        "    Dense(256),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='mean_squared_error',\n",
        "              metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])"
      ],
      "metadata": {
        "id": "ljFX0zGyZwRl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(preprocessed_X, Y, epochs=100, batch_size=32)\n"
      ],
      "metadata": {
        "id": "-MMEj1QQaqV1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f591b568-7510-4eb6-e6e7-7708955b703d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "46/46 [==============================] - 2s 28ms/step - loss: 16445958144.0000 - rmse: 128241.7969\n",
            "Epoch 2/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 1359577216.0000 - rmse: 36872.4453\n",
            "Epoch 3/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 1145257216.0000 - rmse: 33841.6484\n",
            "Epoch 4/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 971708800.0000 - rmse: 31172.2441\n",
            "Epoch 5/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 924358912.0000 - rmse: 30403.2715\n",
            "Epoch 6/100\n",
            "46/46 [==============================] - 2s 35ms/step - loss: 844043520.0000 - rmse: 29052.4277\n",
            "Epoch 7/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 804236992.0000 - rmse: 28359.0723\n",
            "Epoch 8/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 766191360.0000 - rmse: 27680.1621\n",
            "Epoch 9/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 808384256.0000 - rmse: 28432.0996\n",
            "Epoch 10/100\n",
            "46/46 [==============================] - 1s 26ms/step - loss: 894066624.0000 - rmse: 29900.9473\n",
            "Epoch 11/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 760104512.0000 - rmse: 27569.9922\n",
            "Epoch 12/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 782536384.0000 - rmse: 27973.8516\n",
            "Epoch 13/100\n",
            "46/46 [==============================] - 1s 26ms/step - loss: 783197568.0000 - rmse: 27985.6680\n",
            "Epoch 14/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 730742656.0000 - rmse: 27032.2520\n",
            "Epoch 15/100\n",
            "46/46 [==============================] - 2s 35ms/step - loss: 710208320.0000 - rmse: 26649.7344\n",
            "Epoch 16/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 815090368.0000 - rmse: 28549.7871\n",
            "Epoch 17/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 816755776.0000 - rmse: 28578.9395\n",
            "Epoch 18/100\n",
            "46/46 [==============================] - 1s 26ms/step - loss: 756793088.0000 - rmse: 27509.8730\n",
            "Epoch 19/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 739528128.0000 - rmse: 27194.2656\n",
            "Epoch 20/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 700249856.0000 - rmse: 26462.2344\n",
            "Epoch 21/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 867146240.0000 - rmse: 29447.3477\n",
            "Epoch 22/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 777406720.0000 - rmse: 27882.0137\n",
            "Epoch 23/100\n",
            "46/46 [==============================] - 1s 32ms/step - loss: 703118016.0000 - rmse: 26516.3730\n",
            "Epoch 24/100\n",
            "46/46 [==============================] - 1s 32ms/step - loss: 687014720.0000 - rmse: 26210.9648\n",
            "Epoch 25/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 683123904.0000 - rmse: 26136.6387\n",
            "Epoch 26/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 704110528.0000 - rmse: 26535.0820\n",
            "Epoch 27/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 688489856.0000 - rmse: 26239.0898\n",
            "Epoch 28/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 809144064.0000 - rmse: 28445.4570\n",
            "Epoch 29/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 689648576.0000 - rmse: 26261.1602\n",
            "Epoch 30/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 689131840.0000 - rmse: 26251.3203\n",
            "Epoch 31/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 746946944.0000 - rmse: 27330.3301\n",
            "Epoch 32/100\n",
            "46/46 [==============================] - 2s 35ms/step - loss: 690047744.0000 - rmse: 26268.7598\n",
            "Epoch 33/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 756842112.0000 - rmse: 27510.7637\n",
            "Epoch 34/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 690384384.0000 - rmse: 26275.1660\n",
            "Epoch 35/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 639404032.0000 - rmse: 25286.4395\n",
            "Epoch 36/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 682821312.0000 - rmse: 26130.8496\n",
            "Epoch 37/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 707556864.0000 - rmse: 26599.9414\n",
            "Epoch 38/100\n",
            "46/46 [==============================] - 1s 26ms/step - loss: 682998016.0000 - rmse: 26134.2305\n",
            "Epoch 39/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 669385856.0000 - rmse: 25872.4922\n",
            "Epoch 40/100\n",
            "46/46 [==============================] - 1s 26ms/step - loss: 714260544.0000 - rmse: 26725.6523\n",
            "Epoch 41/100\n",
            "46/46 [==============================] - 2s 37ms/step - loss: 689457600.0000 - rmse: 26257.5254\n",
            "Epoch 42/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 665407296.0000 - rmse: 25795.4902\n",
            "Epoch 43/100\n",
            "46/46 [==============================] - 1s 26ms/step - loss: 651353856.0000 - rmse: 25521.6348\n",
            "Epoch 44/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 710325056.0000 - rmse: 26651.9238\n",
            "Epoch 45/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 727803392.0000 - rmse: 26977.8320\n",
            "Epoch 46/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 652988480.0000 - rmse: 25553.6387\n",
            "Epoch 47/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 674357184.0000 - rmse: 25968.3887\n",
            "Epoch 48/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 666023104.0000 - rmse: 25807.4238\n",
            "Epoch 49/100\n",
            "46/46 [==============================] - 1s 26ms/step - loss: 644731648.0000 - rmse: 25391.5664\n",
            "Epoch 50/100\n",
            "46/46 [==============================] - 2s 36ms/step - loss: 650463104.0000 - rmse: 25504.1777\n",
            "Epoch 51/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 608303296.0000 - rmse: 24663.8047\n",
            "Epoch 52/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 736997440.0000 - rmse: 27147.6973\n",
            "Epoch 53/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 658265856.0000 - rmse: 25656.6914\n",
            "Epoch 54/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 665297984.0000 - rmse: 25793.3711\n",
            "Epoch 55/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 690811840.0000 - rmse: 26283.2988\n",
            "Epoch 56/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 676182336.0000 - rmse: 26003.5059\n",
            "Epoch 57/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 617813120.0000 - rmse: 24855.8477\n",
            "Epoch 58/100\n",
            "46/46 [==============================] - 1s 33ms/step - loss: 640767488.0000 - rmse: 25313.3848\n",
            "Epoch 59/100\n",
            "46/46 [==============================] - 1s 32ms/step - loss: 631919808.0000 - rmse: 25138.0156\n",
            "Epoch 60/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 747691840.0000 - rmse: 27343.9551\n",
            "Epoch 61/100\n",
            "46/46 [==============================] - 2s 43ms/step - loss: 651196608.0000 - rmse: 25518.5547\n",
            "Epoch 62/100\n",
            "46/46 [==============================] - 2s 33ms/step - loss: 637385152.0000 - rmse: 25246.4883\n",
            "Epoch 63/100\n",
            "46/46 [==============================] - 2s 36ms/step - loss: 616286016.0000 - rmse: 24825.1094\n",
            "Epoch 64/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 667216128.0000 - rmse: 25830.5273\n",
            "Epoch 65/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 593867328.0000 - rmse: 24369.3926\n",
            "Epoch 66/100\n",
            "46/46 [==============================] - 2s 37ms/step - loss: 597473728.0000 - rmse: 24443.2754\n",
            "Epoch 67/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 620796352.0000 - rmse: 24915.7852\n",
            "Epoch 68/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 618884800.0000 - rmse: 24877.3945\n",
            "Epoch 69/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 610410560.0000 - rmse: 24706.4883\n",
            "Epoch 70/100\n",
            "46/46 [==============================] - 1s 26ms/step - loss: 649863552.0000 - rmse: 25492.4219\n",
            "Epoch 71/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 641264896.0000 - rmse: 25323.2090\n",
            "Epoch 72/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 624173248.0000 - rmse: 24983.4590\n",
            "Epoch 73/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 731968960.0000 - rmse: 27054.9258\n",
            "Epoch 74/100\n",
            "46/46 [==============================] - 1s 29ms/step - loss: 618818752.0000 - rmse: 24876.0684\n",
            "Epoch 75/100\n",
            "46/46 [==============================] - 2s 35ms/step - loss: 659963008.0000 - rmse: 25689.7461\n",
            "Epoch 76/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 654213504.0000 - rmse: 25577.5977\n",
            "Epoch 77/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 630754752.0000 - rmse: 25114.8320\n",
            "Epoch 78/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 652437504.0000 - rmse: 25542.8555\n",
            "Epoch 79/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 670847232.0000 - rmse: 25900.7188\n",
            "Epoch 80/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 679774912.0000 - rmse: 26072.4941\n",
            "Epoch 81/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 696468480.0000 - rmse: 26390.6895\n",
            "Epoch 82/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 593522368.0000 - rmse: 24362.3145\n",
            "Epoch 83/100\n",
            "46/46 [==============================] - 2s 34ms/step - loss: 626194048.0000 - rmse: 25023.8691\n",
            "Epoch 84/100\n",
            "46/46 [==============================] - 1s 31ms/step - loss: 625563456.0000 - rmse: 25011.2656\n",
            "Epoch 85/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 648793920.0000 - rmse: 25471.4336\n",
            "Epoch 86/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 642966336.0000 - rmse: 25356.7812\n",
            "Epoch 87/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 653345600.0000 - rmse: 25560.6250\n",
            "Epoch 88/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 650260864.0000 - rmse: 25500.2129\n",
            "Epoch 89/100\n",
            "46/46 [==============================] - 1s 28ms/step - loss: 618260480.0000 - rmse: 24864.8438\n",
            "Epoch 90/100\n",
            "46/46 [==============================] - 1s 26ms/step - loss: 630023936.0000 - rmse: 25100.2773\n",
            "Epoch 91/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 599167744.0000 - rmse: 24477.9023\n",
            "Epoch 92/100\n",
            "46/46 [==============================] - 2s 37ms/step - loss: 652929024.0000 - rmse: 25552.4766\n",
            "Epoch 93/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 602698432.0000 - rmse: 24549.9180\n",
            "Epoch 94/100\n",
            "46/46 [==============================] - 1s 26ms/step - loss: 615840960.0000 - rmse: 24816.1426\n",
            "Epoch 95/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 637371648.0000 - rmse: 25246.2207\n",
            "Epoch 96/100\n",
            "46/46 [==============================] - 1s 26ms/step - loss: 621587520.0000 - rmse: 24931.6562\n",
            "Epoch 97/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 571262592.0000 - rmse: 23901.0996\n",
            "Epoch 98/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 601861376.0000 - rmse: 24532.8633\n",
            "Epoch 99/100\n",
            "46/46 [==============================] - 1s 27ms/step - loss: 769504064.0000 - rmse: 27739.9355\n",
            "Epoch 100/100\n",
            "46/46 [==============================] - 1s 26ms/step - loss: 591522112.0000 - rmse: 24321.2285\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a5df4032ce0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicton"
      ],
      "metadata": {
        "id": "GVeqLTu95CfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read train data\n",
        "\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "ids = test_df['Id'].values.astype(int)\n",
        "test_df = replace_nans(test_df)\n",
        "preprocessed_test_df, Y  = preprocessDataset(test_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "oBYQYMvy5EmZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(preprocessed_test_df.shape)\n",
        "\n",
        "unique_to_preprocessed_df = preprocessed_df.columns.difference(preprocessed_test_df.columns)\n",
        "#print(unique_to_preprocessed_df)\n",
        "\n",
        "# Populate difference of columns in test_Df\n",
        "for column in unique_to_preprocessed_df:\n",
        "    preprocessed_test_df[column] = 0\n",
        "\n",
        "# maintain order of the columns too:\n",
        "ordered_columns = [col for col in preprocessed_df.columns if col in preprocessed_test_df.columns]\n",
        "\n",
        "preprocessed_test_df = preprocessed_test_df[ordered_columns]\n",
        "\n",
        "# check difference again:\n",
        "unique_to_preprocessed_df = preprocessed_df.columns.difference(preprocessed_test_df.columns)\n",
        "#print(unique_to_preprocessed_df)\n",
        "\n",
        "#print(\"Shape of train: \" + str(preprocessed_df.shape) + \" Shape of test: \" + str(preprocessed_test_df.shape))\n",
        "\n"
      ],
      "metadata": {
        "id": "evWooZrz6a2H"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(preprocessed_test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6apA9BKm5NOY",
        "outputId": "5fbf942a-7a5f-4acc-a7c6-3e7a52a420e6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 0s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate predictions with ids and store to file.\n",
        "\n",
        "result = np.column_stack((ids, predictions))\n",
        "\n",
        "print(\"Predictions shape: \" + str(predictions.shape))\n",
        "print(\"ids shape: \" + str(ids.shape))\n",
        "print(\"result shape: \" + str(result.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_migelCQ6T3X",
        "outputId": "fe6f5b09-67f3-42ab-ea71-b20fc891df5e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions shape: (1459, 1)\n",
            "ids shape: (1459,)\n",
            "result shape: (1459, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "result_df = pd.DataFrame(result, columns=['Id', 'SalePrice'])\n",
        "result_df['Id'] = result_df['Id'].astype(int)\n",
        "\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "result_df.to_csv('predictions.csv', index=False)\n"
      ],
      "metadata": {
        "id": "3CSbpZB1-mei"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oM4fncpSED14"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}