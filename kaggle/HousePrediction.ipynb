{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyON5xQ9WFCc1a865q+0inKT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Add Imports"
      ],
      "metadata": {
        "id": "Fb-MSCDkOYQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "import sklearn.linear_model\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "iHLhJwHZOZtG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e88965fd-954e-42cd-bc8e-0a0429a485bc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read dataset and print the shapes"
      ],
      "metadata": {
        "id": "x9ae3KsfOemE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "feature_names = df.columns\n",
        "X = df.iloc[:, :-1].values\n",
        "Y = df.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "pfU-HUKTRabe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Feature Names: \")\n",
        "print(feature_names)\n",
        "print(\"Features Matrix (X):\")\n",
        "print(X[:2])\n",
        "print(\"Feature vector size: \")\n",
        "print(X.shape)\n",
        "print(\"\\nTarget Vector (Y):\")\n",
        "print(Y[:2])"
      ],
      "metadata": {
        "id": "uwfPMEg2OxOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef7ed56b-bda9-4ec3-c8ab-156fed7a6a9b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Names: \n",
            "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
            "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
            "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
            "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
            "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
            "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
            "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
            "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
            "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
            "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
            "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
            "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
            "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
            "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
            "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
            "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
            "       'SaleCondition', 'SalePrice'],\n",
            "      dtype='object')\n",
            "Features Matrix (X):\n",
            "[[1 60 'RL' 65.0 8450 'Pave' nan 'Reg' 'Lvl' 'AllPub' 'Inside' 'Gtl'\n",
            "  'CollgCr' 'Norm' 'Norm' '1Fam' '2Story' 7 5 2003 2003 'Gable' 'CompShg'\n",
            "  'VinylSd' 'VinylSd' 'BrkFace' 196.0 'Gd' 'TA' 'PConc' 'Gd' 'TA' 'No'\n",
            "  'GLQ' 706 'Unf' 0 150 856 'GasA' 'Ex' 'Y' 'SBrkr' 856 854 0 1710 1 0 2\n",
            "  1 3 1 'Gd' 8 'Typ' 0 nan 'Attchd' 2003.0 'RFn' 2 548 'TA' 'TA' 'Y' 0 61\n",
            "  0 0 0 0 nan nan nan 0 2 2008 'WD' 'Normal']\n",
            " [2 20 'RL' 80.0 9600 'Pave' nan 'Reg' 'Lvl' 'AllPub' 'FR2' 'Gtl'\n",
            "  'Veenker' 'Feedr' 'Norm' '1Fam' '1Story' 6 8 1976 1976 'Gable'\n",
            "  'CompShg' 'MetalSd' 'MetalSd' 'None' 0.0 'TA' 'TA' 'CBlock' 'Gd' 'TA'\n",
            "  'Gd' 'ALQ' 978 'Unf' 0 284 1262 'GasA' 'Ex' 'Y' 'SBrkr' 1262 0 0 1262 0\n",
            "  1 2 0 3 1 'TA' 6 'Typ' 1 'TA' 'Attchd' 1976.0 'RFn' 2 460 'TA' 'TA' 'Y'\n",
            "  298 0 0 0 0 0 nan nan nan 0 5 2007 'WD' 'Normal']]\n",
            "Feature vector size: \n",
            "(1460, 80)\n",
            "\n",
            "Target Vector (Y):\n",
            "[208500 181500]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### See features"
      ],
      "metadata": {
        "id": "2JtuGb15OmvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### See Unique values per column"
      ],
      "metadata": {
        "id": "A9fJyyGMS3rS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_ranges(series, num_bins=20):\n",
        "    min_val, max_val = series.min(), series.max()\n",
        "    range_step = (max_val - min_val) / num_bins\n",
        "    ranges = [f\"{min_val + range_step * i:.2f} - {min_val + range_step * (i+1):.2f}\" for i in range(num_bins)]\n",
        "    return ranges\n",
        "\n",
        "def print_ranges(df):\n",
        "  for column in df.columns:\n",
        "      unique_values = df[column].unique()\n",
        "\n",
        "      if unique_values.size > 20 and np.issubdtype(df[column].dtype, np.number):\n",
        "            print(f\"Column '{column}' has more than 20 unique numeric values. Creating ranges:\")\n",
        "            print(create_ranges(df[column]))\n",
        "      else:\n",
        "        print(f\"Unique values in '{column}':\")\n",
        "        print(unique_values)\n",
        "      print()\n",
        "\n",
        "#print_ranges(df)"
      ],
      "metadata": {
        "id": "LJsRjbfQOpLx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Check for Nans"
      ],
      "metadata": {
        "id": "OQymkpXSbZaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_nans(df):\n",
        "  df_numeric = df.select_dtypes(include=[np.number])\n",
        "  df[df_numeric.columns] = df_numeric.fillna(0)\n",
        "  return df\n",
        "\n",
        "df = replace_nans(df)"
      ],
      "metadata": {
        "id": "zovtjadPboCP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering"
      ],
      "metadata": {
        "id": "16eNG8YcOp1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessDataset(df):\n",
        "  numerical_data = df.select_dtypes(include=['int64', 'float64'])\n",
        "  categorical_data = df.select_dtypes(include=['object'])\n",
        "\n",
        "  sale_price_col = pd.DataFrame()\n",
        "  if 'SalePrice' in df.columns:\n",
        "    sale_price_col = df.SalePrice\n",
        "\n",
        "\n",
        "  # One hot encoding for categories\n",
        "  categorical_data_encoded = pd.get_dummies(categorical_data)\n",
        "\n",
        "  # Apply Standard Scaling to numerical data\n",
        "  scaler = StandardScaler()\n",
        "  numerical_data_scaled = scaler.fit_transform(numerical_data)\n",
        "  numerical_data_scaled_df = pd.DataFrame(numerical_data_scaled, columns=numerical_data.columns)\n",
        "\n",
        "  preprocessed_df = pd.concat([numerical_data_scaled_df, categorical_data_encoded], axis=1)\n",
        "  preprocessed_df.drop('Id', axis=1, inplace=True)\n",
        "  if 'SalePrice' in df.columns:\n",
        "    preprocessed_df.drop('SalePrice', axis=1, inplace=True)\n",
        "  return preprocessed_df, sale_price_col\n",
        "\n",
        "preprocessed_df, Y = preprocessDataset(df)\n"
      ],
      "metadata": {
        "id": "QiNJmrnROtFd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_X = preprocessed_df.iloc[:, :].values\n"
      ],
      "metadata": {
        "id": "IzigsJNq7fek"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(preprocessed_X.shape)\n",
        "\n",
        "print(\"examples preprocessed_X:\")\n",
        "print(preprocessed_X[:2])\n",
        "\n",
        "print(Y.shape)\n",
        "print(\"examples of Y: \")\n",
        "print(Y[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aabSEXKg6kfq",
        "outputId": "059737bc-3ebd-4fcd-f26e-ccac6b9c986d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1460, 288)\n",
            "examples preprocessed_X:\n",
            "[[ 0.07337496  0.2128772  -0.20714171  0.65147924 -0.51719981  1.05099379\n",
            "   0.87866809  0.51410389  0.57542484 -0.28865283 -0.94459061 -0.45930254\n",
            "  -0.79343379  1.16185159 -0.12024172  0.37033344  1.10781015 -0.24106104\n",
            "   0.78974052  1.22758538  0.16377912 -0.21145358  0.91220977 -0.95122649\n",
            "   0.29602618  0.31172464  0.35100032 -0.75217584  0.21650316 -0.3593249\n",
            "  -0.11633929 -0.27020835 -0.06869175 -0.08768781 -1.5991111   0.13877749\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   1.          0.          0.          0.          0.          0.\n",
            "   1.          0.          0.          0.          1.          1.\n",
            "   0.          0.          0.          0.          0.          1.\n",
            "   1.          0.          0.          0.          0.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   1.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   1.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          1.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          0.\n",
            "   0.          1.          0.          0.          1.          0.\n",
            "   0.          0.          0.          0.          1.          0.\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   0.          1.          0.          0.          1.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          1.          0.          1.          0.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          1.          0.          0.          1.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   1.          0.          0.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          0.\n",
            "   1.          0.          0.          1.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          1.          0.        ]\n",
            " [-0.87256276  0.64574726 -0.09188637 -0.07183611  2.17962776  0.15673371\n",
            "  -0.42957697 -0.57075013  1.17199212 -0.28865283 -0.64122799  0.46646492\n",
            "   0.25714043 -0.79516323 -0.12024172 -0.48251191 -0.81996437  3.94880935\n",
            "   0.78974052 -0.76162067  0.16377912 -0.21145358 -0.31868327  0.60049493\n",
            "   0.23649474  0.31172464 -0.06073101  1.62619479 -0.70448325 -0.3593249\n",
            "  -0.11633929 -0.27020835 -0.06869175 -0.08768781 -0.48911005 -0.61443862\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   1.          0.          0.          0.          0.          0.\n",
            "   1.          0.          0.          0.          1.          1.\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   1.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          1.          0.          1.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   0.          0.          0.          0.          1.          0.\n",
            "   0.          0.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          1.          0.          1.          0.          0.\n",
            "   0.          0.          0.          0.          1.          0.\n",
            "   0.          0.          0.          1.          0.          1.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          1.          0.          1.          0.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   1.          0.          0.          0.          0.          1.\n",
            "   0.          1.          0.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          0.\n",
            "   1.          0.          0.          1.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          1.          0.        ]]\n",
            "(1460,)\n",
            "examples of Y: \n",
            "0    208500\n",
            "1    181500\n",
            "Name: SalePrice, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train"
      ],
      "metadata": {
        "id": "xRjhQu2DZryX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (preprocessed_X.shape[1],)\n",
        "model = Sequential([\n",
        "    Dense(8096, input_shape=input_shape),\n",
        "    Dense(4048),\n",
        "    Dense(2024),\n",
        "    Dense(1024),\n",
        "    Dense(512),\n",
        "    Dense(256),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='mean_squared_error',\n",
        "              metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])"
      ],
      "metadata": {
        "id": "ljFX0zGyZwRl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(preprocessed_X, Y, epochs=100, batch_size=32)\n"
      ],
      "metadata": {
        "id": "-MMEj1QQaqV1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f2f5da6-562d-43ae-d39b-f562c0f7a0ef"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "46/46 [==============================] - 39s 823ms/step - loss: 6334774272.0000 - rmse: 79591.2969\n",
            "Epoch 2/100\n",
            "46/46 [==============================] - 38s 829ms/step - loss: 3370339072.0000 - rmse: 58054.6211\n",
            "Epoch 3/100\n",
            "46/46 [==============================] - 38s 823ms/step - loss: 1300145408.0000 - rmse: 36057.5273\n",
            "Epoch 4/100\n",
            "46/46 [==============================] - 37s 812ms/step - loss: 1117472512.0000 - rmse: 33428.6172\n",
            "Epoch 5/100\n",
            "46/46 [==============================] - 38s 817ms/step - loss: 1149692544.0000 - rmse: 33907.1172\n",
            "Epoch 6/100\n",
            "46/46 [==============================] - 37s 812ms/step - loss: 1290831232.0000 - rmse: 35928.1406\n",
            "Epoch 7/100\n",
            "46/46 [==============================] - 37s 797ms/step - loss: 1015829568.0000 - rmse: 31872.0820\n",
            "Epoch 8/100\n",
            "46/46 [==============================] - 37s 808ms/step - loss: 973159168.0000 - rmse: 31195.5000\n",
            "Epoch 9/100\n",
            "46/46 [==============================] - 37s 809ms/step - loss: 801589248.0000 - rmse: 28312.3516\n",
            "Epoch 10/100\n",
            "46/46 [==============================] - 38s 817ms/step - loss: 1187506176.0000 - rmse: 34460.2109\n",
            "Epoch 11/100\n",
            "46/46 [==============================] - 37s 814ms/step - loss: 857345280.0000 - rmse: 29280.4590\n",
            "Epoch 12/100\n",
            "46/46 [==============================] - 38s 821ms/step - loss: 912477632.0000 - rmse: 30207.2441\n",
            "Epoch 13/100\n",
            "46/46 [==============================] - 37s 813ms/step - loss: 1175584640.0000 - rmse: 34286.8008\n",
            "Epoch 14/100\n",
            "46/46 [==============================] - 38s 831ms/step - loss: 996422336.0000 - rmse: 31566.1582\n",
            "Epoch 15/100\n",
            "46/46 [==============================] - 38s 819ms/step - loss: 1299458816.0000 - rmse: 36048.0078\n",
            "Epoch 16/100\n",
            "46/46 [==============================] - 37s 799ms/step - loss: 1450358144.0000 - rmse: 38083.5664\n",
            "Epoch 17/100\n",
            "46/46 [==============================] - 38s 821ms/step - loss: 1053669952.0000 - rmse: 32460.2832\n",
            "Epoch 18/100\n",
            "46/46 [==============================] - 38s 830ms/step - loss: 818966208.0000 - rmse: 28617.5859\n",
            "Epoch 19/100\n",
            "46/46 [==============================] - 38s 827ms/step - loss: 932811968.0000 - rmse: 30541.9707\n",
            "Epoch 20/100\n",
            "46/46 [==============================] - 38s 825ms/step - loss: 712538880.0000 - rmse: 26693.4238\n",
            "Epoch 21/100\n",
            "46/46 [==============================] - 38s 826ms/step - loss: 914513216.0000 - rmse: 30240.9199\n",
            "Epoch 22/100\n",
            "46/46 [==============================] - 38s 823ms/step - loss: 851357632.0000 - rmse: 29178.0332\n",
            "Epoch 23/100\n",
            "46/46 [==============================] - 38s 828ms/step - loss: 812653760.0000 - rmse: 28507.0820\n",
            "Epoch 24/100\n",
            "46/46 [==============================] - 38s 831ms/step - loss: 899551872.0000 - rmse: 29992.5293\n",
            "Epoch 25/100\n",
            "46/46 [==============================] - 38s 826ms/step - loss: 886159040.0000 - rmse: 29768.4238\n",
            "Epoch 26/100\n",
            "46/46 [==============================] - 37s 815ms/step - loss: 864447680.0000 - rmse: 29401.4902\n",
            "Epoch 27/100\n",
            "46/46 [==============================] - 37s 798ms/step - loss: 900082496.0000 - rmse: 30001.3750\n",
            "Epoch 28/100\n",
            "46/46 [==============================] - 37s 809ms/step - loss: 1163041024.0000 - rmse: 34103.3867\n",
            "Epoch 29/100\n",
            "46/46 [==============================] - 38s 821ms/step - loss: 772894848.0000 - rmse: 27800.9863\n",
            "Epoch 30/100\n",
            "46/46 [==============================] - 38s 820ms/step - loss: 779767616.0000 - rmse: 27924.3203\n",
            "Epoch 31/100\n",
            "46/46 [==============================] - 38s 827ms/step - loss: 762085184.0000 - rmse: 27605.8906\n",
            "Epoch 32/100\n",
            "46/46 [==============================] - 38s 823ms/step - loss: 946342080.0000 - rmse: 30762.6738\n",
            "Epoch 33/100\n",
            "46/46 [==============================] - 38s 823ms/step - loss: 665105856.0000 - rmse: 25789.6465\n",
            "Epoch 34/100\n",
            "46/46 [==============================] - 38s 822ms/step - loss: 762436736.0000 - rmse: 27612.2578\n",
            "Epoch 35/100\n",
            "46/46 [==============================] - 38s 821ms/step - loss: 1066227520.0000 - rmse: 32653.1387\n",
            "Epoch 36/100\n",
            "46/46 [==============================] - 37s 805ms/step - loss: 871535424.0000 - rmse: 29521.7793\n",
            "Epoch 37/100\n",
            "46/46 [==============================] - 38s 810ms/step - loss: 706116480.0000 - rmse: 26572.8516\n",
            "Epoch 38/100\n",
            "46/46 [==============================] - 38s 818ms/step - loss: 680813120.0000 - rmse: 26092.3965\n",
            "Epoch 39/100\n",
            "46/46 [==============================] - 38s 817ms/step - loss: 869218304.0000 - rmse: 29482.5078\n",
            "Epoch 40/100\n",
            "46/46 [==============================] - 37s 812ms/step - loss: 747127360.0000 - rmse: 27333.6309\n",
            "Epoch 41/100\n",
            "46/46 [==============================] - 37s 810ms/step - loss: 776245888.0000 - rmse: 27861.1895\n",
            "Epoch 42/100\n",
            "46/46 [==============================] - 38s 834ms/step - loss: 686293824.0000 - rmse: 26197.2109\n",
            "Epoch 43/100\n",
            "46/46 [==============================] - 49s 1s/step - loss: 706029952.0000 - rmse: 26571.2246\n",
            "Epoch 44/100\n",
            "46/46 [==============================] - 53s 1s/step - loss: 678436224.0000 - rmse: 26046.8086\n",
            "Epoch 45/100\n",
            "46/46 [==============================] - 55s 1s/step - loss: 685228416.0000 - rmse: 26176.8672\n",
            "Epoch 46/100\n",
            "46/46 [==============================] - 62s 1s/step - loss: 718220544.0000 - rmse: 26799.6367\n",
            "Epoch 47/100\n",
            "46/46 [==============================] - 61s 1s/step - loss: 835214336.0000 - rmse: 28900.0742\n",
            "Epoch 48/100\n",
            "46/46 [==============================] - 65s 1s/step - loss: 662525504.0000 - rmse: 25739.5703\n",
            "Epoch 49/100\n",
            "46/46 [==============================] - 47s 1s/step - loss: 696572480.0000 - rmse: 26392.6602\n",
            "Epoch 50/100\n",
            "46/46 [==============================] - 40s 866ms/step - loss: 836884672.0000 - rmse: 28928.9590\n",
            "Epoch 51/100\n",
            "46/46 [==============================] - 37s 798ms/step - loss: 1063652608.0000 - rmse: 32613.6875\n",
            "Epoch 52/100\n",
            "46/46 [==============================] - 36s 779ms/step - loss: 705049664.0000 - rmse: 26552.7715\n",
            "Epoch 53/100\n",
            "46/46 [==============================] - 36s 779ms/step - loss: 649228544.0000 - rmse: 25479.9629\n",
            "Epoch 54/100\n",
            "46/46 [==============================] - 36s 788ms/step - loss: 675021440.0000 - rmse: 25981.1738\n",
            "Epoch 55/100\n",
            "46/46 [==============================] - 36s 773ms/step - loss: 761725120.0000 - rmse: 27599.3672\n",
            "Epoch 56/100\n",
            "46/46 [==============================] - 38s 803ms/step - loss: 692539136.0000 - rmse: 26316.1387\n",
            "Epoch 57/100\n",
            "46/46 [==============================] - 38s 822ms/step - loss: 690090688.0000 - rmse: 26269.5781\n",
            "Epoch 58/100\n",
            "46/46 [==============================] - 38s 823ms/step - loss: 698017408.0000 - rmse: 26420.0195\n",
            "Epoch 59/100\n",
            "46/46 [==============================] - 38s 832ms/step - loss: 679742336.0000 - rmse: 26071.8691\n",
            "Epoch 60/100\n",
            "46/46 [==============================] - 38s 817ms/step - loss: 663878976.0000 - rmse: 25765.8496\n",
            "Epoch 61/100\n",
            "46/46 [==============================] - 37s 812ms/step - loss: 738546176.0000 - rmse: 27176.2070\n",
            "Epoch 62/100\n",
            "46/46 [==============================] - 38s 820ms/step - loss: 634940864.0000 - rmse: 25198.0332\n",
            "Epoch 63/100\n",
            "46/46 [==============================] - 38s 819ms/step - loss: 835154048.0000 - rmse: 28899.0312\n",
            "Epoch 64/100\n",
            "46/46 [==============================] - 38s 821ms/step - loss: 639850752.0000 - rmse: 25295.2715\n",
            "Epoch 65/100\n",
            "46/46 [==============================] - 38s 822ms/step - loss: 786083136.0000 - rmse: 28037.1738\n",
            "Epoch 66/100\n",
            "46/46 [==============================] - 37s 815ms/step - loss: 800972544.0000 - rmse: 28301.4590\n",
            "Epoch 67/100\n",
            "46/46 [==============================] - 38s 835ms/step - loss: 711610560.0000 - rmse: 26676.0293\n",
            "Epoch 68/100\n",
            "46/46 [==============================] - 38s 831ms/step - loss: 806469056.0000 - rmse: 28398.3984\n",
            "Epoch 69/100\n",
            "46/46 [==============================] - 38s 832ms/step - loss: 741599616.0000 - rmse: 27232.3262\n",
            "Epoch 70/100\n",
            "46/46 [==============================] - 37s 800ms/step - loss: 593252416.0000 - rmse: 24356.7734\n",
            "Epoch 71/100\n",
            "46/46 [==============================] - 36s 785ms/step - loss: 682966656.0000 - rmse: 26133.6309\n",
            "Epoch 72/100\n",
            "46/46 [==============================] - 36s 774ms/step - loss: 653259584.0000 - rmse: 25558.9434\n",
            "Epoch 73/100\n",
            "46/46 [==============================] - 36s 778ms/step - loss: 680446080.0000 - rmse: 26085.3613\n",
            "Epoch 74/100\n",
            "46/46 [==============================] - 35s 770ms/step - loss: 693541312.0000 - rmse: 26335.1719\n",
            "Epoch 75/100\n",
            "46/46 [==============================] - 37s 799ms/step - loss: 672333312.0000 - rmse: 25929.3906\n",
            "Epoch 76/100\n",
            "46/46 [==============================] - 37s 798ms/step - loss: 645575808.0000 - rmse: 25408.1836\n",
            "Epoch 77/100\n",
            "46/46 [==============================] - 38s 824ms/step - loss: 671833344.0000 - rmse: 25919.7480\n",
            "Epoch 78/100\n",
            "46/46 [==============================] - 39s 846ms/step - loss: 854256128.0000 - rmse: 29227.6602\n",
            "Epoch 79/100\n",
            "46/46 [==============================] - 39s 849ms/step - loss: 710112768.0000 - rmse: 26647.9414\n",
            "Epoch 80/100\n",
            "46/46 [==============================] - 38s 838ms/step - loss: 662196224.0000 - rmse: 25733.1738\n",
            "Epoch 81/100\n",
            "46/46 [==============================] - 40s 862ms/step - loss: 662016320.0000 - rmse: 25729.6777\n",
            "Epoch 82/100\n",
            "46/46 [==============================] - 39s 845ms/step - loss: 756685824.0000 - rmse: 27507.9238\n",
            "Epoch 83/100\n",
            "46/46 [==============================] - 40s 865ms/step - loss: 685669184.0000 - rmse: 26185.2852\n",
            "Epoch 84/100\n",
            "46/46 [==============================] - 39s 840ms/step - loss: 936163456.0000 - rmse: 30596.7891\n",
            "Epoch 85/100\n",
            "46/46 [==============================] - 36s 789ms/step - loss: 690188608.0000 - rmse: 26271.4414\n",
            "Epoch 86/100\n",
            "46/46 [==============================] - 36s 784ms/step - loss: 754795968.0000 - rmse: 27473.5508\n",
            "Epoch 87/100\n",
            "46/46 [==============================] - 36s 775ms/step - loss: 956210112.0000 - rmse: 30922.6465\n",
            "Epoch 88/100\n",
            "46/46 [==============================] - 36s 769ms/step - loss: 657433600.0000 - rmse: 25640.4688\n",
            "Epoch 89/100\n",
            "46/46 [==============================] - 38s 819ms/step - loss: 662622976.0000 - rmse: 25741.4648\n",
            "Epoch 90/100\n",
            "46/46 [==============================] - 36s 789ms/step - loss: 721329152.0000 - rmse: 26857.5723\n",
            "Epoch 91/100\n",
            "46/46 [==============================] - 35s 764ms/step - loss: 662436160.0000 - rmse: 25737.8359\n",
            "Epoch 92/100\n",
            "46/46 [==============================] - 35s 771ms/step - loss: 777812928.0000 - rmse: 27889.2969\n",
            "Epoch 93/100\n",
            "46/46 [==============================] - 38s 817ms/step - loss: 682733696.0000 - rmse: 26129.1738\n",
            "Epoch 94/100\n",
            "46/46 [==============================] - 39s 856ms/step - loss: 633183680.0000 - rmse: 25163.1406\n",
            "Epoch 95/100\n",
            "46/46 [==============================] - 44s 967ms/step - loss: 771056640.0000 - rmse: 27767.9062\n",
            "Epoch 96/100\n",
            "46/46 [==============================] - 45s 982ms/step - loss: 639760832.0000 - rmse: 25293.4941\n",
            "Epoch 97/100\n",
            "46/46 [==============================] - 45s 970ms/step - loss: 638806016.0000 - rmse: 25274.6113\n",
            "Epoch 98/100\n",
            "46/46 [==============================] - 45s 982ms/step - loss: 795830400.0000 - rmse: 28210.4668\n",
            "Epoch 99/100\n",
            "46/46 [==============================] - 45s 978ms/step - loss: 657678144.0000 - rmse: 25645.2363\n",
            "Epoch 100/100\n",
            "46/46 [==============================] - 45s 972ms/step - loss: 746845376.0000 - rmse: 27328.4727\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e3bfd186590>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicton"
      ],
      "metadata": {
        "id": "GVeqLTu95CfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read train data\n",
        "\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "ids = test_df['Id'].values.astype(int)\n",
        "test_df = replace_nans(test_df)\n",
        "preprocessed_test_df, Y  = preprocessDataset(test_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "oBYQYMvy5EmZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(preprocessed_test_df.shape)\n",
        "\n",
        "unique_to_preprocessed_df = preprocessed_df.columns.difference(preprocessed_test_df.columns)\n",
        "#print(unique_to_preprocessed_df)\n",
        "\n",
        "# Populate difference of columns in test_Df\n",
        "for column in unique_to_preprocessed_df:\n",
        "    preprocessed_test_df[column] = 0\n",
        "\n",
        "# maintain order of the columns too:\n",
        "ordered_columns = [col for col in preprocessed_df.columns if col in preprocessed_test_df.columns]\n",
        "\n",
        "preprocessed_test_df = preprocessed_test_df[ordered_columns]\n",
        "\n",
        "# check difference again:\n",
        "unique_to_preprocessed_df = preprocessed_df.columns.difference(preprocessed_test_df.columns)\n",
        "#print(unique_to_preprocessed_df)\n",
        "\n",
        "#print(\"Shape of train: \" + str(preprocessed_df.shape) + \" Shape of test: \" + str(preprocessed_test_df.shape))\n",
        "\n"
      ],
      "metadata": {
        "id": "evWooZrz6a2H"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(preprocessed_test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6apA9BKm5NOY",
        "outputId": "4ff0f7d3-b4b3-4d00-9428-9ba58eb9f730"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 8s 179ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate predictions with ids and store to file.\n",
        "\n",
        "result = np.column_stack((ids, predictions))\n",
        "\n",
        "print(\"Predictions shape: \" + str(predictions.shape))\n",
        "print(\"ids shape: \" + str(ids.shape))\n",
        "print(\"result shape: \" + str(result.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_migelCQ6T3X",
        "outputId": "726e0795-2a22-44fc-bae1-31d9c1fead65"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions shape: (1459, 1)\n",
            "ids shape: (1459,)\n",
            "result shape: (1459, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "result_df = pd.DataFrame(result, columns=['Id', 'SalePrice'])\n",
        "result_df['Id'] = result_df['Id'].astype(int)\n",
        "\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "result_df.to_csv('predictions.csv', index=False)\n"
      ],
      "metadata": {
        "id": "3CSbpZB1-mei"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oM4fncpSED14"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}