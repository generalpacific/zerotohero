{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbnkc6u4HO59FWxajWIJWO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Add Imports"
      ],
      "metadata": {
        "id": "Fb-MSCDkOYQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "import sklearn.linear_model\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "iHLhJwHZOZtG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04b963f3-b756-4771-a7a4-503e09308420"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read dataset and print the shapes"
      ],
      "metadata": {
        "id": "x9ae3KsfOemE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "feature_names = df.columns\n",
        "X = df.iloc[:, :-1].values\n",
        "Y = df.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "pfU-HUKTRabe"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Feature Names: \")\n",
        "print(feature_names)\n",
        "print(\"Features Matrix (X):\")\n",
        "print(X[:2])\n",
        "print(\"Feature vector size: \")\n",
        "print(X.shape)\n",
        "print(\"\\nTarget Vector (Y):\")\n",
        "print(Y[:2])"
      ],
      "metadata": {
        "id": "uwfPMEg2OxOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90dc3b26-e277-4047-a22c-6a203b666333"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Names: \n",
            "Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
            "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
            "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n",
            "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
            "       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
            "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
            "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
            "       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
            "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
            "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
            "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
            "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',\n",
            "       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',\n",
            "       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
            "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',\n",
            "       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
            "       'SaleCondition', 'SalePrice'],\n",
            "      dtype='object')\n",
            "Features Matrix (X):\n",
            "[[1 60 'RL' 65.0 8450 'Pave' nan 'Reg' 'Lvl' 'AllPub' 'Inside' 'Gtl'\n",
            "  'CollgCr' 'Norm' 'Norm' '1Fam' '2Story' 7 5 2003 2003 'Gable' 'CompShg'\n",
            "  'VinylSd' 'VinylSd' 'BrkFace' 196.0 'Gd' 'TA' 'PConc' 'Gd' 'TA' 'No'\n",
            "  'GLQ' 706 'Unf' 0 150 856 'GasA' 'Ex' 'Y' 'SBrkr' 856 854 0 1710 1 0 2\n",
            "  1 3 1 'Gd' 8 'Typ' 0 nan 'Attchd' 2003.0 'RFn' 2 548 'TA' 'TA' 'Y' 0 61\n",
            "  0 0 0 0 nan nan nan 0 2 2008 'WD' 'Normal']\n",
            " [2 20 'RL' 80.0 9600 'Pave' nan 'Reg' 'Lvl' 'AllPub' 'FR2' 'Gtl'\n",
            "  'Veenker' 'Feedr' 'Norm' '1Fam' '1Story' 6 8 1976 1976 'Gable'\n",
            "  'CompShg' 'MetalSd' 'MetalSd' 'None' 0.0 'TA' 'TA' 'CBlock' 'Gd' 'TA'\n",
            "  'Gd' 'ALQ' 978 'Unf' 0 284 1262 'GasA' 'Ex' 'Y' 'SBrkr' 1262 0 0 1262 0\n",
            "  1 2 0 3 1 'TA' 6 'Typ' 1 'TA' 'Attchd' 1976.0 'RFn' 2 460 'TA' 'TA' 'Y'\n",
            "  298 0 0 0 0 0 nan nan nan 0 5 2007 'WD' 'Normal']]\n",
            "Feature vector size: \n",
            "(1460, 80)\n",
            "\n",
            "Target Vector (Y):\n",
            "[208500 181500]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### See features"
      ],
      "metadata": {
        "id": "2JtuGb15OmvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### See Unique values per column"
      ],
      "metadata": {
        "id": "A9fJyyGMS3rS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_ranges(series, num_bins=20):\n",
        "    min_val, max_val = series.min(), series.max()\n",
        "    range_step = (max_val - min_val) / num_bins\n",
        "    ranges = [f\"{min_val + range_step * i:.2f} - {min_val + range_step * (i+1):.2f}\" for i in range(num_bins)]\n",
        "    return ranges\n",
        "\n",
        "def print_ranges(df):\n",
        "  for column in df.columns:\n",
        "      unique_values = df[column].unique()\n",
        "\n",
        "      if unique_values.size > 20 and np.issubdtype(df[column].dtype, np.number):\n",
        "            print(f\"Column '{column}' has more than 20 unique numeric values. Creating ranges:\")\n",
        "            print(create_ranges(df[column]))\n",
        "      else:\n",
        "        print(f\"Unique values in '{column}':\")\n",
        "        print(unique_values)\n",
        "      print()\n",
        "\n",
        "#print_ranges(df)"
      ],
      "metadata": {
        "id": "LJsRjbfQOpLx"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Check for Nans"
      ],
      "metadata": {
        "id": "OQymkpXSbZaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_nans(df):\n",
        "  df_numeric = df.select_dtypes(include=[np.number])\n",
        "  df[df_numeric.columns] = df_numeric.fillna(0)\n",
        "  return df\n",
        "\n",
        "df = replace_nans(df)"
      ],
      "metadata": {
        "id": "zovtjadPboCP"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Engineering"
      ],
      "metadata": {
        "id": "16eNG8YcOp1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessDataset(df):\n",
        "  numerical_data = df.select_dtypes(include=['int64', 'float64'])\n",
        "  categorical_data = df.select_dtypes(include=['object'])\n",
        "\n",
        "  sale_price_col = pd.DataFrame()\n",
        "  if 'SalePrice' in df.columns:\n",
        "    sale_price_col = df.SalePrice\n",
        "\n",
        "\n",
        "  # One hot encoding for categories\n",
        "  categorical_data_encoded = pd.get_dummies(categorical_data)\n",
        "\n",
        "  # Apply Standard Scaling to numerical data\n",
        "  scaler = StandardScaler()\n",
        "  numerical_data_scaled = scaler.fit_transform(numerical_data)\n",
        "  numerical_data_scaled_df = pd.DataFrame(numerical_data_scaled, columns=numerical_data.columns)\n",
        "\n",
        "  preprocessed_df = pd.concat([numerical_data_scaled_df, categorical_data_encoded], axis=1)\n",
        "  preprocessed_df.drop('Id', axis=1, inplace=True)\n",
        "  if 'SalePrice' in df.columns:\n",
        "    preprocessed_df.drop('SalePrice', axis=1, inplace=True)\n",
        "  return preprocessed_df, sale_price_col\n",
        "\n",
        "preprocessed_df, Y = preprocessDataset(df)\n"
      ],
      "metadata": {
        "id": "QiNJmrnROtFd"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_X = preprocessed_df.iloc[:, :].values\n"
      ],
      "metadata": {
        "id": "IzigsJNq7fek"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(preprocessed_X.shape)\n",
        "\n",
        "print(\"examples preprocessed_X:\")\n",
        "print(preprocessed_X[:2])\n",
        "\n",
        "print(Y.shape)\n",
        "print(\"examples of Y: \")\n",
        "print(Y[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aabSEXKg6kfq",
        "outputId": "c7b3446d-5fa8-4bae-84c9-96ebd2d01276"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1460, 288)\n",
            "examples preprocessed_X:\n",
            "[[ 0.07337496  0.2128772  -0.20714171  0.65147924 -0.51719981  1.05099379\n",
            "   0.87866809  0.51410389  0.57542484 -0.28865283 -0.94459061 -0.45930254\n",
            "  -0.79343379  1.16185159 -0.12024172  0.37033344  1.10781015 -0.24106104\n",
            "   0.78974052  1.22758538  0.16377912 -0.21145358  0.91220977 -0.95122649\n",
            "   0.29602618  0.31172464  0.35100032 -0.75217584  0.21650316 -0.3593249\n",
            "  -0.11633929 -0.27020835 -0.06869175 -0.08768781 -1.5991111   0.13877749\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   1.          0.          0.          0.          0.          0.\n",
            "   1.          0.          0.          0.          1.          1.\n",
            "   0.          0.          0.          0.          0.          1.\n",
            "   1.          0.          0.          0.          0.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   1.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   1.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          1.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          0.\n",
            "   0.          1.          0.          0.          1.          0.\n",
            "   0.          0.          0.          0.          1.          0.\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   0.          1.          0.          0.          1.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          1.          0.          1.          0.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          1.          0.          0.          1.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   1.          0.          0.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          0.\n",
            "   1.          0.          0.          1.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          1.          0.        ]\n",
            " [-0.87256276  0.64574726 -0.09188637 -0.07183611  2.17962776  0.15673371\n",
            "  -0.42957697 -0.57075013  1.17199212 -0.28865283 -0.64122799  0.46646492\n",
            "   0.25714043 -0.79516323 -0.12024172 -0.48251191 -0.81996437  3.94880935\n",
            "   0.78974052 -0.76162067  0.16377912 -0.21145358 -0.31868327  0.60049493\n",
            "   0.23649474  0.31172464 -0.06073101  1.62619479 -0.70448325 -0.3593249\n",
            "  -0.11633929 -0.27020835 -0.06869175 -0.08768781 -0.48911005 -0.61443862\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   1.          0.          0.          0.          0.          0.\n",
            "   1.          0.          0.          0.          1.          1.\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   1.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          1.          0.          1.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   0.          0.          0.          0.          1.          0.\n",
            "   0.          0.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          1.          0.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          1.          0.          1.          0.          0.\n",
            "   0.          0.          0.          0.          1.          0.\n",
            "   0.          0.          0.          1.          0.          1.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          1.          0.          1.          0.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          0.          1.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   1.          0.          0.          0.          0.          1.\n",
            "   0.          1.          0.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          0.\n",
            "   0.          1.          0.          0.          0.          0.\n",
            "   1.          0.          0.          1.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          0.\n",
            "   0.          0.          0.          0.          0.          1.\n",
            "   0.          0.          0.          0.          1.          0.        ]]\n",
            "(1460,)\n",
            "examples of Y: \n",
            "0    208500\n",
            "1    181500\n",
            "Name: SalePrice, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train"
      ],
      "metadata": {
        "id": "xRjhQu2DZryX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (preprocessed_X.shape[1],)\n",
        "model = Sequential([\n",
        "    Dense(4048, input_shape=input_shape),\n",
        "    Dense(2024),\n",
        "    Dense(1024),\n",
        "    Dense(512),\n",
        "    Dense(256),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='mean_squared_error',\n",
        "              metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])"
      ],
      "metadata": {
        "id": "ljFX0zGyZwRl"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(preprocessed_X, Y, epochs=100, batch_size=32)\n"
      ],
      "metadata": {
        "id": "-MMEj1QQaqV1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86d84cd1-c78a-42b5-d703-9d850a2d7255"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "46/46 [==============================] - 5s 94ms/step - loss: 10054113280.0000 - rmse: 100270.2031\n",
            "Epoch 2/100\n",
            "46/46 [==============================] - 4s 90ms/step - loss: 1281145472.0000 - rmse: 35793.0938\n",
            "Epoch 3/100\n",
            "46/46 [==============================] - 4s 98ms/step - loss: 1176423296.0000 - rmse: 34299.0273\n",
            "Epoch 4/100\n",
            "46/46 [==============================] - 4s 91ms/step - loss: 1003384000.0000 - rmse: 31676.2363\n",
            "Epoch 5/100\n",
            "46/46 [==============================] - 5s 100ms/step - loss: 872427328.0000 - rmse: 29536.8809\n",
            "Epoch 6/100\n",
            "46/46 [==============================] - 4s 89ms/step - loss: 1007866496.0000 - rmse: 31746.9141\n",
            "Epoch 7/100\n",
            "46/46 [==============================] - 4s 94ms/step - loss: 935604480.0000 - rmse: 30587.6523\n",
            "Epoch 8/100\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 906960448.0000 - rmse: 30115.7832\n",
            "Epoch 9/100\n",
            "46/46 [==============================] - 4s 84ms/step - loss: 902934016.0000 - rmse: 30048.8613\n",
            "Epoch 10/100\n",
            "46/46 [==============================] - 4s 83ms/step - loss: 826587136.0000 - rmse: 28750.4277\n",
            "Epoch 11/100\n",
            "46/46 [==============================] - 4s 89ms/step - loss: 876289856.0000 - rmse: 29602.1934\n",
            "Epoch 12/100\n",
            "46/46 [==============================] - 4s 80ms/step - loss: 800355008.0000 - rmse: 28290.5469\n",
            "Epoch 13/100\n",
            "46/46 [==============================] - 4s 82ms/step - loss: 1015583936.0000 - rmse: 31868.2285\n",
            "Epoch 14/100\n",
            "46/46 [==============================] - 4s 92ms/step - loss: 770677760.0000 - rmse: 27761.0840\n",
            "Epoch 15/100\n",
            "46/46 [==============================] - 4s 82ms/step - loss: 790009984.0000 - rmse: 28107.1172\n",
            "Epoch 16/100\n",
            "46/46 [==============================] - 4s 90ms/step - loss: 886381056.0000 - rmse: 29772.1523\n",
            "Epoch 17/100\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 856596288.0000 - rmse: 29267.6660\n",
            "Epoch 18/100\n",
            "46/46 [==============================] - 4s 84ms/step - loss: 825422208.0000 - rmse: 28730.1621\n",
            "Epoch 19/100\n",
            "46/46 [==============================] - 5s 98ms/step - loss: 774951168.0000 - rmse: 27837.9453\n",
            "Epoch 20/100\n",
            "46/46 [==============================] - 4s 85ms/step - loss: 844359104.0000 - rmse: 29057.8574\n",
            "Epoch 21/100\n",
            "46/46 [==============================] - 4s 82ms/step - loss: 771305408.0000 - rmse: 27772.3848\n",
            "Epoch 22/100\n",
            "46/46 [==============================] - 4s 87ms/step - loss: 800137536.0000 - rmse: 28286.7031\n",
            "Epoch 23/100\n",
            "46/46 [==============================] - 4s 94ms/step - loss: 756446336.0000 - rmse: 27503.5703\n",
            "Epoch 24/100\n",
            "46/46 [==============================] - 4s 86ms/step - loss: 767770688.0000 - rmse: 27708.6758\n",
            "Epoch 25/100\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 1020475712.0000 - rmse: 31944.8848\n",
            "Epoch 26/100\n",
            "46/46 [==============================] - 4s 90ms/step - loss: 820040448.0000 - rmse: 28636.3477\n",
            "Epoch 27/100\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 705360256.0000 - rmse: 26558.6191\n",
            "Epoch 28/100\n",
            "46/46 [==============================] - 4s 90ms/step - loss: 747734592.0000 - rmse: 27344.7363\n",
            "Epoch 29/100\n",
            "46/46 [==============================] - 4s 95ms/step - loss: 780270080.0000 - rmse: 27933.3145\n",
            "Epoch 30/100\n",
            "46/46 [==============================] - 5s 103ms/step - loss: 758615360.0000 - rmse: 27542.9727\n",
            "Epoch 31/100\n",
            "46/46 [==============================] - 4s 90ms/step - loss: 728846976.0000 - rmse: 26997.1660\n",
            "Epoch 32/100\n",
            "46/46 [==============================] - 4s 93ms/step - loss: 751656576.0000 - rmse: 27416.3555\n",
            "Epoch 33/100\n",
            "46/46 [==============================] - 5s 98ms/step - loss: 817806848.0000 - rmse: 28597.3223\n",
            "Epoch 34/100\n",
            "46/46 [==============================] - 4s 91ms/step - loss: 749772928.0000 - rmse: 27381.9824\n",
            "Epoch 35/100\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 768815552.0000 - rmse: 27727.5234\n",
            "Epoch 36/100\n",
            "46/46 [==============================] - 4s 93ms/step - loss: 792833152.0000 - rmse: 28157.2930\n",
            "Epoch 37/100\n",
            "46/46 [==============================] - 4s 84ms/step - loss: 705299200.0000 - rmse: 26557.4707\n",
            "Epoch 38/100\n",
            "46/46 [==============================] - 4s 91ms/step - loss: 670212736.0000 - rmse: 25888.4668\n",
            "Epoch 39/100\n",
            "46/46 [==============================] - 4s 84ms/step - loss: 821577536.0000 - rmse: 28663.1738\n",
            "Epoch 40/100\n",
            "46/46 [==============================] - 4s 82ms/step - loss: 880551360.0000 - rmse: 29674.0859\n",
            "Epoch 41/100\n",
            "46/46 [==============================] - 4s 91ms/step - loss: 847174464.0000 - rmse: 29106.2617\n",
            "Epoch 42/100\n",
            "46/46 [==============================] - 4s 83ms/step - loss: 779568256.0000 - rmse: 27920.7500\n",
            "Epoch 43/100\n",
            "46/46 [==============================] - 4s 82ms/step - loss: 731948480.0000 - rmse: 27054.5469\n",
            "Epoch 44/100\n",
            "46/46 [==============================] - 4s 90ms/step - loss: 719229184.0000 - rmse: 26818.4492\n",
            "Epoch 45/100\n",
            "46/46 [==============================] - 4s 87ms/step - loss: 841171904.0000 - rmse: 29002.9629\n",
            "Epoch 46/100\n",
            "46/46 [==============================] - 4s 94ms/step - loss: 756641664.0000 - rmse: 27507.1211\n",
            "Epoch 47/100\n",
            "46/46 [==============================] - 4s 92ms/step - loss: 769118208.0000 - rmse: 27732.9805\n",
            "Epoch 48/100\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 985034688.0000 - rmse: 31385.2617\n",
            "Epoch 49/100\n",
            "46/46 [==============================] - 4s 95ms/step - loss: 758670784.0000 - rmse: 27543.9785\n",
            "Epoch 50/100\n",
            "46/46 [==============================] - 4s 93ms/step - loss: 714617600.0000 - rmse: 26732.3320\n",
            "Epoch 51/100\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 704990784.0000 - rmse: 26551.6621\n",
            "Epoch 52/100\n",
            "46/46 [==============================] - 5s 99ms/step - loss: 690136512.0000 - rmse: 26270.4492\n",
            "Epoch 53/100\n",
            "46/46 [==============================] - 4s 91ms/step - loss: 654633984.0000 - rmse: 25585.8164\n",
            "Epoch 54/100\n",
            "46/46 [==============================] - 5s 101ms/step - loss: 629204992.0000 - rmse: 25083.9590\n",
            "Epoch 55/100\n",
            "46/46 [==============================] - 4s 81ms/step - loss: 623017728.0000 - rmse: 24960.3223\n",
            "Epoch 56/100\n",
            "46/46 [==============================] - 4s 85ms/step - loss: 698949760.0000 - rmse: 26437.6582\n",
            "Epoch 57/100\n",
            "46/46 [==============================] - 4s 89ms/step - loss: 925734272.0000 - rmse: 30425.8809\n",
            "Epoch 58/100\n",
            "46/46 [==============================] - 4s 86ms/step - loss: 718749696.0000 - rmse: 26809.5078\n",
            "Epoch 59/100\n",
            "46/46 [==============================] - 4s 87ms/step - loss: 604396032.0000 - rmse: 24584.4668\n",
            "Epoch 60/100\n",
            "46/46 [==============================] - 4s 91ms/step - loss: 748902016.0000 - rmse: 27366.0742\n",
            "Epoch 61/100\n",
            "46/46 [==============================] - 4s 83ms/step - loss: 690002048.0000 - rmse: 26267.8906\n",
            "Epoch 62/100\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 708934592.0000 - rmse: 26625.8262\n",
            "Epoch 63/100\n",
            "46/46 [==============================] - 4s 90ms/step - loss: 756242176.0000 - rmse: 27499.8574\n",
            "Epoch 64/100\n",
            "46/46 [==============================] - 4s 85ms/step - loss: 891967872.0000 - rmse: 29865.8320\n",
            "Epoch 65/100\n",
            "46/46 [==============================] - 4s 93ms/step - loss: 677366208.0000 - rmse: 26026.2598\n",
            "Epoch 66/100\n",
            "46/46 [==============================] - 4s 82ms/step - loss: 665750208.0000 - rmse: 25802.1348\n",
            "Epoch 67/100\n",
            "46/46 [==============================] - 4s 82ms/step - loss: 778939072.0000 - rmse: 27909.4805\n",
            "Epoch 68/100\n",
            "46/46 [==============================] - 5s 104ms/step - loss: 637935040.0000 - rmse: 25257.3750\n",
            "Epoch 69/100\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 801353088.0000 - rmse: 28308.1797\n",
            "Epoch 70/100\n",
            "46/46 [==============================] - 4s 97ms/step - loss: 769140928.0000 - rmse: 27733.3906\n",
            "Epoch 71/100\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 860019712.0000 - rmse: 29326.0918\n",
            "Epoch 72/100\n",
            "46/46 [==============================] - 4s 80ms/step - loss: 628749824.0000 - rmse: 25074.8848\n",
            "Epoch 73/100\n",
            "46/46 [==============================] - 4s 82ms/step - loss: 662939584.0000 - rmse: 25747.6133\n",
            "Epoch 74/100\n",
            "46/46 [==============================] - 4s 85ms/step - loss: 856262912.0000 - rmse: 29261.9707\n",
            "Epoch 75/100\n",
            "46/46 [==============================] - 4s 78ms/step - loss: 846039168.0000 - rmse: 29086.7520\n",
            "Epoch 76/100\n",
            "46/46 [==============================] - 4s 80ms/step - loss: 719780672.0000 - rmse: 26828.7285\n",
            "Epoch 77/100\n",
            "46/46 [==============================] - 4s 92ms/step - loss: 796059584.0000 - rmse: 28214.5273\n",
            "Epoch 78/100\n",
            "46/46 [==============================] - 4s 93ms/step - loss: 673064576.0000 - rmse: 25943.4883\n",
            "Epoch 79/100\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 720368960.0000 - rmse: 26839.6895\n",
            "Epoch 80/100\n",
            "46/46 [==============================] - 4s 86ms/step - loss: 605453248.0000 - rmse: 24605.9590\n",
            "Epoch 81/100\n",
            "46/46 [==============================] - 4s 85ms/step - loss: 649723776.0000 - rmse: 25489.6797\n",
            "Epoch 82/100\n",
            "46/46 [==============================] - 4s 96ms/step - loss: 621326016.0000 - rmse: 24926.4121\n",
            "Epoch 83/100\n",
            "46/46 [==============================] - 4s 82ms/step - loss: 587852864.0000 - rmse: 24245.6777\n",
            "Epoch 84/100\n",
            "46/46 [==============================] - 4s 86ms/step - loss: 649264768.0000 - rmse: 25480.6738\n",
            "Epoch 85/100\n",
            "46/46 [==============================] - 4s 95ms/step - loss: 694227712.0000 - rmse: 26348.2012\n",
            "Epoch 86/100\n",
            "46/46 [==============================] - 4s 92ms/step - loss: 732071872.0000 - rmse: 27056.8262\n",
            "Epoch 87/100\n",
            "46/46 [==============================] - 5s 105ms/step - loss: 673059008.0000 - rmse: 25943.3809\n",
            "Epoch 88/100\n",
            "46/46 [==============================] - 4s 91ms/step - loss: 701348032.0000 - rmse: 26482.9766\n",
            "Epoch 89/100\n",
            "46/46 [==============================] - 4s 82ms/step - loss: 699182080.0000 - rmse: 26442.0508\n",
            "Epoch 90/100\n",
            "46/46 [==============================] - 4s 95ms/step - loss: 633384896.0000 - rmse: 25167.1387\n",
            "Epoch 91/100\n",
            "46/46 [==============================] - 4s 94ms/step - loss: 641444544.0000 - rmse: 25326.7559\n",
            "Epoch 92/100\n",
            "46/46 [==============================] - 4s 92ms/step - loss: 609910336.0000 - rmse: 24696.3633\n",
            "Epoch 93/100\n",
            "46/46 [==============================] - 4s 93ms/step - loss: 706239744.0000 - rmse: 26575.1719\n",
            "Epoch 94/100\n",
            "46/46 [==============================] - 4s 87ms/step - loss: 657805184.0000 - rmse: 25647.7129\n",
            "Epoch 95/100\n",
            "46/46 [==============================] - 4s 82ms/step - loss: 618741504.0000 - rmse: 24874.5156\n",
            "Epoch 96/100\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 693651840.0000 - rmse: 26337.2715\n",
            "Epoch 97/100\n",
            "46/46 [==============================] - 4s 91ms/step - loss: 712605312.0000 - rmse: 26694.6680\n",
            "Epoch 98/100\n",
            "46/46 [==============================] - 5s 102ms/step - loss: 716800960.0000 - rmse: 26773.1387\n",
            "Epoch 99/100\n",
            "46/46 [==============================] - 4s 83ms/step - loss: 631321472.0000 - rmse: 25126.1113\n",
            "Epoch 100/100\n",
            "46/46 [==============================] - 4s 82ms/step - loss: 586401344.0000 - rmse: 24215.7246\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a5df1093f40>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicton"
      ],
      "metadata": {
        "id": "GVeqLTu95CfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read train data\n",
        "\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "ids = test_df['Id'].values.astype(int)\n",
        "test_df = replace_nans(test_df)\n",
        "preprocessed_test_df, Y  = preprocessDataset(test_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "oBYQYMvy5EmZ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(preprocessed_test_df.shape)\n",
        "\n",
        "unique_to_preprocessed_df = preprocessed_df.columns.difference(preprocessed_test_df.columns)\n",
        "#print(unique_to_preprocessed_df)\n",
        "\n",
        "# Populate difference of columns in test_Df\n",
        "for column in unique_to_preprocessed_df:\n",
        "    preprocessed_test_df[column] = 0\n",
        "\n",
        "# maintain order of the columns too:\n",
        "ordered_columns = [col for col in preprocessed_df.columns if col in preprocessed_test_df.columns]\n",
        "\n",
        "preprocessed_test_df = preprocessed_test_df[ordered_columns]\n",
        "\n",
        "# check difference again:\n",
        "unique_to_preprocessed_df = preprocessed_df.columns.difference(preprocessed_test_df.columns)\n",
        "#print(unique_to_preprocessed_df)\n",
        "\n",
        "#print(\"Shape of train: \" + str(preprocessed_df.shape) + \" Shape of test: \" + str(preprocessed_test_df.shape))\n",
        "\n"
      ],
      "metadata": {
        "id": "evWooZrz6a2H"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(preprocessed_test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6apA9BKm5NOY",
        "outputId": "e3355b52-59eb-4997-dbbf-ddf95eeb3325"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 1s 14ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate predictions with ids and store to file.\n",
        "\n",
        "result = np.column_stack((ids, predictions))\n",
        "\n",
        "print(\"Predictions shape: \" + str(predictions.shape))\n",
        "print(\"ids shape: \" + str(ids.shape))\n",
        "print(\"result shape: \" + str(result.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_migelCQ6T3X",
        "outputId": "74e16568-fde7-4f16-ef71-ae1209848e9b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions shape: (1459, 1)\n",
            "ids shape: (1459,)\n",
            "result shape: (1459, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "result_df = pd.DataFrame(result, columns=['Id', 'SalePrice'])\n",
        "result_df['Id'] = result_df['Id'].astype(int)\n",
        "\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "result_df.to_csv('predictions.csv', index=False)\n"
      ],
      "metadata": {
        "id": "3CSbpZB1-mei"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oM4fncpSED14"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}