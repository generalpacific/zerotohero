{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2FmWmbS/v8YH/KtCTJGYI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/generalpacific/zerotohero/blob/main/zerotoherobengio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile dataset for the neural net"
      ],
      "metadata": {
        "id": "F5JEbgNSwh1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt \n",
        "# The %matplotlib inline command tells the IPython environment to draw the plots immediately after the current cell\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "XpfLbWbUwlN8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read dataset in words"
      ],
      "metadata": {
        "id": "fKJmuGka7nOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('sample_data/names.txt', 'r').read().splitlines()\n",
        "words[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0a0Kh2K5p7c",
        "outputId": "ce780fbe-e5bf-446e-9e66-dcb83a9eecd1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma',\n",
              " 'olivia',\n",
              " 'ava',\n",
              " 'isabella',\n",
              " 'sophia',\n",
              " 'charlotte',\n",
              " 'mia',\n",
              " 'amelia',\n",
              " 'harper',\n",
              " 'evelyn']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build mapping of to/from integers"
      ],
      "metadata": {
        "id": "l9E_wfvd6296"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "\n",
        "# character to integer\n",
        "stoi = {s:i + 1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "\n",
        "# integer to character\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "print(itos)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGJvTem16oQq",
        "outputId": "14ce2b9a-6dbe-4e14-c357-3a6fdf3070c7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make the intial data set with the block of input and the next prediction"
      ],
      "metadata": {
        "id": "d3ib8kOe7qTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BLOCK_SIZE = 3\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for w in words:\n",
        "  # Read the block.\n",
        "  current_block = [0] * BLOCK_SIZE\n",
        "\n",
        "  for ch in w + '.':\n",
        "    i = stoi[ch]\n",
        "    X.append(current_block)\n",
        "    Y.append(i)\n",
        "    # print(''.join(itos[ib] for ib in current_block), \" -> \" , ch)\n",
        "    current_block = current_block[1:] + [i]\n",
        "\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)"
      ],
      "metadata": {
        "id": "GHHpnXaf8j_G"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJmktHo-PGJp",
        "outputId": "08f9763a-c40e-4699-faf4-48590341f9c2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([228146, 3]), torch.Size([228146]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding Lookup table \n",
        "* decide the embedding size\n"
      ],
      "metadata": {
        "id": "XBXTnPxgwlqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lookup table with embedding size 2.\n",
        "C = torch.randn(27,2)\n",
        "\n",
        "# embedding is simply the lookup for each input.\n",
        "embedding = C[X]\n"
      ],
      "metadata": {
        "id": "vIyzUSc6xmsn"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP: First Layer\n",
        "* Decide weights and number of neurons for the first layer\n",
        "* challenge will be how do you multiple embedding which is `32 * 3 * 2` matrix by weights which will be `6 * number of neurons` size."
      ],
      "metadata": {
        "id": "oN8brG32DF0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_OF_NEURONS = 100\n",
        "\n",
        "W1 = torch.randn(6, NUM_OF_NEURONS)\n",
        "b1 = torch.randn(NUM_OF_NEURONS)\n",
        "\n",
        "h = torch.tanh(embedding.view(embedding.shape[0], 6) @ W1 + b1)"
      ],
      "metadata": {
        "id": "jImAdusdDIXH"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDXGDm3WFoxQ",
        "outputId": "70956f7f-52ec-4a99-c2b0-2dc524836ada"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.0000,  1.0000,  0.3543,  ..., -1.0000, -0.9524, -0.9405],\n",
              "        [-0.9997, -0.5203,  0.9990,  ..., -1.0000,  1.0000, -0.9230],\n",
              "        [ 0.9993,  0.9993, -1.0000,  ..., -0.9926, -0.8662, -0.1419],\n",
              "        ...,\n",
              "        [-0.9713,  0.6152, -0.7253,  ..., -0.9419,  0.6753,  0.3512],\n",
              "        [-0.9487,  0.9871, -0.8801,  ...,  0.9602, -0.8803, -0.0933],\n",
              "        [-0.9993, -0.1741,  0.9915,  ..., -0.9999,  0.9375, -0.9140]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP: Final layer\n",
        "* Outputs logits.\n",
        "* Normalize the logits so that they sum to one."
      ],
      "metadata": {
        "id": "0ORtcqrFGK_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W2 = torch.randn(NUM_OF_NEURONS, 27)\n",
        "b2 = torch.randn(27)\n",
        "\n",
        "logits = h @ W2 + b2\n",
        "\n",
        "# Normalize logits\n",
        "counts = logits.exp()\n",
        "prob = counts / counts.sum(1, keepdims = True)\n",
        "prob[0].sum() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEmCC6RMGN67",
        "outputId": "bf55bb60-c2f1-4a9c-d766-3806b32e1a5f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0000)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement negative log likelihood loss\n",
        "* Find the prob assigned to Y by the above NN."
      ],
      "metadata": {
        "id": "RC1fppYGHhtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prob_for_Y = prob[torch.arange(32), Y]\n",
        "\n",
        "log_likelyhood = prob_for_Y.log()\n",
        "\n",
        "mean_log_likelyhood = log_likelyhood.mean()\n",
        "\n",
        "# negative log likelyhood\n",
        "loss = -mean_log_likelyhood\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoZA179bHnel",
        "outputId": "e462727b-53ff-4783-f400-90d3d4f59aa4"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(16.1061)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.cross_entropy(logits, Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol3KlBjZIwrS",
        "outputId": "5b49210f-17f1-48f1-a65e-40be751e6956"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(15.8593)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model: Lets redefine parameters with same seed.\n"
      ],
      "metadata": {
        "id": "y2R6DfgIIZl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(1232132)\n",
        "\n",
        "# Lookup table with embedding size 2.\n",
        "C = torch.randn((27, 2), generator=g)\n",
        "\n",
        "NUM_OF_NEURONS = 100\n",
        "\n",
        "W1 = torch.randn((6, NUM_OF_NEURONS), generator=g)\n",
        "b1 = torch.randn((NUM_OF_NEURONS), generator=g)\n",
        "\n",
        "W2 = torch.randn((NUM_OF_NEURONS, 27), generator=g)\n",
        "b2 = torch.randn((27), generator=g)\n",
        "\n"
      ],
      "metadata": {
        "id": "iGERrf2SKda0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "zttemoJEJeH0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model: Forward pass and backward pass on minibatch"
      ],
      "metadata": {
        "id": "ouppKEZsLXY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "LEARNING_RATE = 0.1\n",
        "TRAINING_PASSES = 1000\n",
        "MINI_BATCH_SIZE = 32\n",
        "\n",
        "for _ in range(TRAINING_PASSES):\n",
        "  # Construct minibatch\n",
        "  mini_batch = torch.randint(0, X.shape[0], (MINI_BATCH_SIZE,))\n",
        "\n",
        "\n",
        "  # forward pass\n",
        "  embedding = C[X[mini_batch]]\n",
        "  h = torch.tanh(embedding.view(-1, 6) @ W1 + b1)\n",
        "  logits = h @ W2 + b2\n",
        "  loss = F.cross_entropy(logits, Y[mini_batch])\n",
        "\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "\n",
        "  # backward pass\n",
        "  loss.backward()\n",
        "  for p in parameters:\n",
        "    p.data += (-LEARNING_RATE) * p.grad\n",
        "\n",
        "print(loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAp0PJQfLaOb",
        "outputId": "0f7e75f3-1b29-4ca9-e278-b47560ba1af1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.643733263015747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss on the whole dataset"
      ],
      "metadata": {
        "id": "wmeehZwkRTx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = C[X]\n",
        "h = torch.tanh(embedding.view(-1, 6) @ W1 + b1)\n",
        "logits = h @ W2 + b2\n",
        "loss = F.cross_entropy(logits, Y)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dJdkbFZRWWd",
        "outputId": "5fcca810-6e71-4a8f-eb84-d6c5fc302b2f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.5391, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample outputs from the neural net.\n"
      ],
      "metadata": {
        "id": "6SEwiN87RzbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "    \n",
        "    out = []\n",
        "    block = [0] * BLOCK_SIZE # initialize with all ...\n",
        "    while True:\n",
        "      emb = C[torch.tensor([block])] # (1,block_size,d)\n",
        "      h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
        "      logits = h @ W2 + b2\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      if ix == 0:\n",
        "        break\n",
        "    \n",
        "    print(''.join(itos[i] for i in out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QgFtIxlR3At",
        "outputId": "0215d4ea-01b5-49f8-b61a-885c6f0d6f42"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mria.\n",
            "kayanhiee.\n",
            "med.\n",
            "ryalo.\n",
            "etursi.\n",
            "jdrlen.\n",
            "adened.\n",
            "elii.\n",
            "eli.\n",
            "jenlekeineananar.\n",
            "katzimhotaa.\n",
            "nosadhergahiries.\n",
            "kinir.\n",
            "jellenntenorou.\n",
            "zenedar.\n",
            "ylene.\n",
            "eha.\n",
            "kae.\n",
            "mustoyan.\n",
            "hal.\n"
          ]
        }
      ]
    }
  ]
}