{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN75EM1yOk95OiJwdcPLsEH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/generalpacific/zerotohero/blob/main/zerotoherobengio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile dataset for the neural net"
      ],
      "metadata": {
        "id": "F5JEbgNSwh1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt \n",
        "# The %matplotlib inline command tells the IPython environment to draw the plots immediately after the current cell\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "XpfLbWbUwlN8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read dataset in words"
      ],
      "metadata": {
        "id": "fKJmuGka7nOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('sample_data/names.txt', 'r').read().splitlines()\n",
        "words[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0a0Kh2K5p7c",
        "outputId": "8516d684-7b1f-4939-a502-12eddba53230"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma',\n",
              " 'olivia',\n",
              " 'ava',\n",
              " 'isabella',\n",
              " 'sophia',\n",
              " 'charlotte',\n",
              " 'mia',\n",
              " 'amelia',\n",
              " 'harper',\n",
              " 'evelyn']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build mapping of to/from integers"
      ],
      "metadata": {
        "id": "l9E_wfvd6296"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "\n",
        "# character to integer\n",
        "stoi = {s:i + 1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "\n",
        "# integer to character\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "print(itos)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGJvTem16oQq",
        "outputId": "4f928345-59b2-403c-8b7f-ca046d339c58"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make the intial data set with the block of input and the next prediction"
      ],
      "metadata": {
        "id": "d3ib8kOe7qTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BLOCK_SIZE = 3\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for w in words[:5]:\n",
        "  print(w)\n",
        "\n",
        "  # Read the block.\n",
        "  current_block = [0] * BLOCK_SIZE\n",
        "\n",
        "  for ch in w + '.':\n",
        "    i = stoi[ch]\n",
        "    X.append(current_block)\n",
        "    Y.append(i)\n",
        "    print(''.join(itos[ib] for ib in current_block), \" -> \" , ch)\n",
        "    current_block = current_block[1:] + [i]\n",
        "\n",
        "  print (\"\\n\")\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHHpnXaf8j_G",
        "outputId": "ace08332-69d1-47b5-c9d2-7f5af26ee546"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emma\n",
            "...  ->  e\n",
            "..e  ->  m\n",
            ".em  ->  m\n",
            "emm  ->  a\n",
            "mma  ->  .\n",
            "\n",
            "\n",
            "olivia\n",
            "...  ->  o\n",
            "..o  ->  l\n",
            ".ol  ->  i\n",
            "oli  ->  v\n",
            "liv  ->  i\n",
            "ivi  ->  a\n",
            "via  ->  .\n",
            "\n",
            "\n",
            "ava\n",
            "...  ->  a\n",
            "..a  ->  v\n",
            ".av  ->  a\n",
            "ava  ->  .\n",
            "\n",
            "\n",
            "isabella\n",
            "...  ->  i\n",
            "..i  ->  s\n",
            ".is  ->  a\n",
            "isa  ->  b\n",
            "sab  ->  e\n",
            "abe  ->  l\n",
            "bel  ->  l\n",
            "ell  ->  a\n",
            "lla  ->  .\n",
            "\n",
            "\n",
            "sophia\n",
            "...  ->  s\n",
            "..s  ->  o\n",
            ".so  ->  p\n",
            "sop  ->  h\n",
            "oph  ->  i\n",
            "phi  ->  a\n",
            "hia  ->  .\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding Lookup table \n",
        "* decide the embedding size\n"
      ],
      "metadata": {
        "id": "XBXTnPxgwlqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lookup table with embedding size 2.\n",
        "C = torch.randn(27,2)\n",
        "\n",
        "# embedding is simply the lookup for each input.\n",
        "embedding = C[X]\n"
      ],
      "metadata": {
        "id": "vIyzUSc6xmsn"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP: First Layer\n",
        "* Decide weights and number of neurons for the first layer\n",
        "* challenge will be how do you multiple embedding which is `32 * 3 * 2` matrix by weights which will be `6 * number of neurons` size."
      ],
      "metadata": {
        "id": "oN8brG32DF0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_OF_NEURONS = 100\n",
        "\n",
        "W1 = torch.randn(6, NUM_OF_NEURONS)\n",
        "b1 = torch.randn(NUM_OF_NEURONS)\n",
        "\n",
        "h = torch.tanh(embedding.view(embedding.shape[0], 6) @ W1 + b1)"
      ],
      "metadata": {
        "id": "jImAdusdDIXH"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDXGDm3WFoxQ",
        "outputId": "70956f7f-52ec-4a99-c2b0-2dc524836ada"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.0000,  1.0000,  0.3543,  ..., -1.0000, -0.9524, -0.9405],\n",
              "        [-0.9997, -0.5203,  0.9990,  ..., -1.0000,  1.0000, -0.9230],\n",
              "        [ 0.9993,  0.9993, -1.0000,  ..., -0.9926, -0.8662, -0.1419],\n",
              "        ...,\n",
              "        [-0.9713,  0.6152, -0.7253,  ..., -0.9419,  0.6753,  0.3512],\n",
              "        [-0.9487,  0.9871, -0.8801,  ...,  0.9602, -0.8803, -0.0933],\n",
              "        [-0.9993, -0.1741,  0.9915,  ..., -0.9999,  0.9375, -0.9140]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP: Final layer\n",
        "* Outputs logits.\n",
        "* Normalize the logits so that they sum to one."
      ],
      "metadata": {
        "id": "0ORtcqrFGK_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W2 = torch.randn(NUM_OF_NEURONS, 27)\n",
        "b2 = torch.randn(27)\n",
        "\n",
        "logits = h @ W2 + b2\n",
        "\n",
        "# Normalize logits\n",
        "counts = logits.exp()\n",
        "prob = counts / counts.sum(1, keepdims = True)\n",
        "prob[0].sum() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEmCC6RMGN67",
        "outputId": "bf55bb60-c2f1-4a9c-d766-3806b32e1a5f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0000)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement negative log likelihood loss\n",
        "* Find the prob assigned to Y by the above NN."
      ],
      "metadata": {
        "id": "RC1fppYGHhtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prob_for_Y = prob[torch.arange(32), Y]\n",
        "\n",
        "log_likelyhood = prob_for_Y.log()\n",
        "\n",
        "mean_log_likelyhood = log_likelyhood.mean()\n",
        "\n",
        "# negative log likelyhood\n",
        "loss = -mean_log_likelyhood\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoZA179bHnel",
        "outputId": "e462727b-53ff-4783-f400-90d3d4f59aa4"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(16.1061)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.cross_entropy(logits, Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol3KlBjZIwrS",
        "outputId": "5b49210f-17f1-48f1-a65e-40be751e6956"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(15.8593)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model: Lets redefine parameters with same seed.\n"
      ],
      "metadata": {
        "id": "y2R6DfgIIZl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(1232132)\n",
        "\n",
        "# Lookup table with embedding size 2.\n",
        "C = torch.randn((27, 2), generator=g)\n",
        "\n",
        "NUM_OF_NEURONS = 100\n",
        "\n",
        "W1 = torch.randn((6, NUM_OF_NEURONS), generator=g)\n",
        "b1 = torch.randn((NUM_OF_NEURONS), generator=g)\n",
        "\n",
        "W2 = torch.randn((NUM_OF_NEURONS, 27), generator=g)\n",
        "b2 = torch.randn((27), generator=g)\n",
        "\n"
      ],
      "metadata": {
        "id": "iGERrf2SKda0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = [C, W1, b1, W2, b2]\n",
        "\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "zttemoJEJeH0"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model: Forward pass and backward pass"
      ],
      "metadata": {
        "id": "ouppKEZsLXY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "LEARNING_RATE = 0.1\n",
        "TRAINING_PASSES = 1000\n",
        "\n",
        "for _ in range(TRAINING_PASSES):\n",
        "  # forward pass\n",
        "  embedding = C[X]\n",
        "  h = torch.tanh(embedding.view(-1, 6) @ W1 + b1)\n",
        "  logits = h @ W2 + b2\n",
        "  loss = F.cross_entropy(logits, Y)\n",
        "\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "\n",
        "  # backward pass\n",
        "  loss.backward()\n",
        "  for p in parameters:\n",
        "    p.data += (-LEARNING_RATE) * p.grad\n",
        "\n",
        "print(loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAp0PJQfLaOb",
        "outputId": "62af3610-2321-43d6-a746-7a8c02742dc7"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2532922625541687\n"
          ]
        }
      ]
    }
  ]
}